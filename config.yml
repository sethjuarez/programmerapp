# pytorch_lightning==1.9.0
seed_everything: true
trainer:
  enable_checkpointing: true
  callbacks:
  - class_path: pytorch_lightning.callbacks.EarlyStopping
    init_args:
      monitor: val_loss
      min_delta: 0.001
      patience: 5
      verbose: True
      mode: min
  - class_path: pytorch_lightning.callbacks.ModelCheckpoint
    init_args:
      monitor: val_acc
      dirpath: outputs/checkpoints
      filename: roshambo-{epoch:02d}-{val_acc:.2f}
      save_top_k: 3
      mode: min
  - class_path: pytorch_lightning.callbacks.LearningRateMonitor
    init_args:
      logging_interval: 'step'
  default_root_dir: outputs
  auto_select_gpus: true
  gpus: 1
  max_epochs: 100
  logger: true
model:
  lr: .1
data:
  mltable_dir: ./data
  batch_size: 256
  train_split: 0.7
